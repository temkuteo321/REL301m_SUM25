# Bối cảnh: kết hợp state aggregation
- Bài giảng dùng state aggregation—gộp các trạng thái tương tự vào một meta-state—để khảo nghiệm tác động lên Gradient Monte Carlo và Semi-gradient TD(0).
- Mục tiêu là phân tích hai phương pháp chính về tốc độ học và sai số khi sử dụng đại diện miền trạng thái đơn giản này.
# Cập nhật với state aggregation:
![image](https://github.com/user-attachments/assets/1f604200-cb2e-4a37-8cc8-60fca35e6e35)
# So sánh thực nghiệm:
![image](https://github.com/user-attachments/assets/50526e92-4fee-42bb-a03d-2f87ebdd913f)
- Nhờ cập nhật sớm và thường xuyên, TD(0) học nhanh và ổn định hơn dù có bias; Monte Carlo thì chuẩn xác hơn về lý thuyết nhưng chậm và thiếu ổn định
# Khả năng tổng quát hóa & phân biệt:
![image](https://github.com/user-attachments/assets/298dcd2b-eabb-4d9c-b75e-d5a6b9d71c6d)
# Kết luận:
![image](https://github.com/user-attachments/assets/f2cae9a5-7906-4aad-bb43-d087ca1fbe12)



